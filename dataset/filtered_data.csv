Name_of_the_topic,Year,Level,Introduction_Summary,Learning_Outcomes,Link_to_the_Summary_Page,Link_to_the_PDF_File,Summary
Big Data Projects,2021,2,"Big data (also referred to as alternative data) encompasses data generated by financial markets (e.g., stock and bond prices), businesses (e.g., company financials, production volumes), governments (e.g., economic and trade data), individuals (e.g., credit card purchases, social media posts), sensors (e.g., satellite imagery, traffic patterns), and the Internet of Things, or IoT, (i.e., the network of interrelated digital devices that can transfer data among themselves without human interaction). A veritable explosion in big data has occurred over the past decade or so, especially in unstructured data generated from social media (e.g., posts, tweets, blogs), email and text communications, web traffic, online news sites, electronic images, and other electronic information sources. The prospects are for exponential growth in big data to continue. Investment managers are increasingly using big data in their investment processes as they strive to discover signals embedded in such data that can provide them with an information edge. They seek to augment structured data with a plethora of unstructured data to develop improved forecasts of trends in asset prices, detect anomalies, etc. A typical example involves a fund manager using financial text data from 10-K reports for forecasting stock sentiment (i.e., positive or negative), which can then be used as an input to a more comprehensive forecasting model that includes corporate financial data. Unlike structured data (numbers and values) that can be readily organized into data tables to be read and analyzed by computers, unstructured data typically require specific methods of preparation and refinement before being usable by machines (i.e., computers) and useful to investment professionals. Given the volume, variety, and velocity of available big data, it is important for portfolio managers and investment analysts to have a basic understanding of how unstructured data can be transformed into structured data suitable as inputs to machine learning (ML) methods (in fact, for any type of modeling methods) that can potentially improve their financial forecasts. This reading describes the steps in using big data, both structured and unstructured, in financial forecasting. The concepts and methods are then demonstrated in a case study of an actual big data project. The project uses text-based data derived from financial documents to train an ML model to classify text into positive or negative sentiment classes for the respective stocks and then to predict sentiment. Section 2 of the reading covers a description of the key characteristics of big data. Section 3 provides an overview of the steps in executing a financial forecasting project using big data. We then describe in Sections 4–6 key aspects of data preparation and wrangling, data exploration, and model training using structured data and unstructured (textual) data. In Section 7, we bring these pieces together by covering the execution of an actual big data project. A summary in Section 8 concludes the reading.","state and explain steps in a data analysis project; describe objectives, steps, and examples of preparing and wrangling data; describe objectives, methods, and examples of data exploration; describe objectives, steps, and techniques in model training; describe preparing, wrangling, and exploring text-based data for financial forecasting; describe methods for extracting, selecting and engineering features from textual data; evaluate the fit of a machine learning algorithm.",https://www.cfainstitute.org/membership/professional-development/refresher-readings/big-data-projects,https://www.cfainstitute.org/-/media/documents/protected/refresher-reading/2021/pdf/big-data-projects.pdf,"Big data—defined as data with volume, velocity, variety, and potentially lower veracity—has tremendous potential for various fintech applications, including several related to investment management. The main steps for traditional ML model building are conceptualization of the problem, data collection, data preparation and wrangling, data exploration, and model training. For textual ML model building, the first four steps differ somewhat from those used in the traditional model: Text problem formulation, text curation, text preparation and wrangling, and text exploration are typically necessary. For structured data, data preparation and wrangling entail data cleansing and data preprocessing. Data cleansing typically involves resolving incompleteness errors, invalidity errors, inaccuracy errors, inconsistency errors, non-uniformity errors, and duplication errors. Preprocessing for structured data typically involves performing the following transformations: extraction, aggregation, filtration, selection, and conversion. Preparation and wrangling text (unstructured) data involves a set of text-specific cleansing and preprocessing tasks. Text cleansing typically involves removing the following: html tags, punctuations, most numbers, and white spaces. Text preprocessing requires performing normalization that involves the following: lowercasing, removing stop words, stemming, lemmatization, creating bag-of-words (BOW) and n-grams, and organizing the BOW and n-grams into a document term matrix (DTM). Data exploration encompasses exploratory data analysis, feature selection, and feature engineering. Whereas histograms, box plots, and scatterplots are common techniques for exploring structured data, word clouds are an effective way to gain a high-level picture of the composition of textual content. These visualization tools help share knowledge among the team (business subject matter experts, quants, technologists, etc.) to help derive optimal solutions. Feature selection methods used for text data include term frequency, document frequency, chi-square test, and a mutual information measure. Feature engineering for text data includes converting numbers into tokens, creating n-grams, and using name entity recognition and parts of speech to engineer new feature variables. The model training steps (method selection, performance evaluation, and model tuning) often do not differ much for structured versus unstructured data projects. Model selection is governed by the following factors: whether the data project involves labeled data (supervised learning) or unlabeled data (unsupervised learning); the type of data (numerical, continuous, or categorical; text data; image data; speech data; etc.); and the size of the dataset. Model performance evaluation involves error analysis using confusion matrixes, determining receiver operating characteristics, and calculating root mean square error. To carry out an error analysis for each model, a confusion matrix is created; true positives (TPs), true negatives (TNs), false positives (FPs), and false negatives (FNs) are determined. Then, the following performance metrics are calculated: accuracy, F1 score, precision, and recall. The higher the accuracy and F1 score, the better the model performance. To carry out receiver operating characteristic (ROC) analysis, ROC curves and area under the curve (AUC) of various models are calculated and compared. The more convex the ROC curve and the higher the AUC, the better the model performance. Model tuning involves managing the trade-off between model bias error, associated with underfitting, and model variance error, associated with overfitting. A fitting curve of in-sample (training sample) error and out-of-sample (cross-validation sample) error on the y-axis versus model complexity on the x-axis is useful for managing the bias vs. variance error trade-off. In a real-world big data project involving text data analysis for classifying and predicting sentiment of financial text for particular stocks, the text data are transformed into structured data for populating the DTM, which is then used as the input for the ML algorithm. To derive term frequency (TF) at the sentence level and TF–IDF, both of which can be inputs to the DTM, the following frequency measures should be used to create a term frequency measures table: TotalWordsInSentence; TotalWordCount; TermFrequency (Collection Level); WordCountInSentence; SentenceCountWithWord; Document Frequency; and Inverse Document Frequency. "
Backtesting & Simulation,2021,2,"This reading provides an overview of backtesting and simulation of investment strategies. Backtesting and related techniques enable investment practitioners to simulate the performance of investment strategies (especially quantitative strategies) using historical data or data derived from the distributions of historical data, to generate test results, and to analyze risk and return, without investing any real capital in the strategies. The rise of big data and the increase in computing power have spurred the development and spread of quantitative investing. Almost every major data vendor has available tools that make systematic backtesting and simulation increasingly accessible. Off-the-shelf software allows backtesting and simulation of endless combinations of possible investment strategies, formulation of multifactor models, and construction of investable portfolios. Developing quantitative investment strategies may appear relatively straightforward, but in reality, it is not. However, understanding the steps and procedures, the implicit assumptions, the pitfalls, and the interpretation of results in backtesting and simulation is a prerequisite for proper utilization of these tools and successful development and implementation of investment strategies. In a CFA Institute survey of nearly 250 analysts, portfolio managers, and private wealth managers on quantitative investment techniques, 50% of respondents reported that they had conducted backtesting of an investment strategy within the past 12 months of the survey date. This result underscores the importance of backtesting (and other simulation techniques) for investors in practice, and this reading is a starting point on the journey to building this core professional competency.",describe objectives in backtesting an investment strategy; describe and contrast steps and procedures in backtesting an investment strategy; interpret metrics and visuals reported in a backtest of an investment strategy; identify problems in a backtest of an investment strategy; describe different ways to construct multifactor models; compare methods of modeling randomness; evaluate and interpret a scenario analysis; contrast Monte Carlo and historical simulation; explain inputs and decisions in simulation and interpret a simulation; and demonstrate the use of sensitivity analysis.,https://www.cfainstitute.org/membership/professional-development/refresher-readings/backtesting-and-simulation,https://www.cfainstitute.org/-/media/documents/protected/refresher-reading/2021/pdf/backtesting-and-simulation.pdf,"In this reading, we have discussed how to perform rolling window backtesting—a widely used technique in the investment industry. Next, we described how to use scenario analysis and simulation along with sensitivity analysis to supplement backtesting, so investors can better account for the randomness in data that may not be fully captured by backtesting. The main objective of backtesting is to understand the risk–return trade-off of an investment strategy, by approximating the real-life investment process. The basic steps in a rolling window backtesting include specifying the investment hypothesis and goals, determining the rules and processes behind an investment strategy, forming an investment portfolio according to the rules, rebalancing the portfolio periodically, and computing the performance and risk profiles of the strategy. In the rolling window backtesting methodology, researchers use a rolling window (or walk-forward) framework, fit/calibrate factors or trade signals based on the rolling window, rebalance the portfolio periodically, and then track the performance over time. Thus, rolling window backtesting is a proxy for actual investing. There are two commonly used approaches in backtesting—long/short hedged portfolio and Spearman rank IC. The two approaches often give similar results, but results can be quite different at times. Choosing the right approach depends on the model building and portfolio construction process. In assessing backtesting results, in addition to traditional performance measurements (e.g., Sharpe ratio, maximum drawdown), analysts need to take into account data coverage, return distribution, factor efficacy, factor turnover, and decay. There are several behavioral issues in backtesting to which analysts need to pay particular attention, including survivorship bias and look-ahead bias. Risk parity is a popular portfolio construction technique that takes into account the volatility of each factor (or asset) and the correlations of returns between all factors (or assets) to be combined in the portfolio. The objective is for each factor (or asset) to make an equal (hence “parity”) risk contribution to the overall or targeted risk of the portfolio. Asset (and factor) returns are often negatively skewed and exhibit excess kurtosis (fat tails) and tail dependence compared with normal distribution. As a result, standard rolling window backtesting may not be able to fully account for the randomness in asset returns, particularly on downside risk. Financial data often face structural breaks. Scenario analysis can help investors understand the performance of an investment strategy in different structural regimes. Historical simulation is relatively straightforward to perform but shares pros and cons similar to those of rolling window backtesting. For example, a key assumption these methods share is that the distribution pattern from the historical data is sufficient to represent the uncertainty in the future. Bootstrapping (or random draws with replacement) is often used in historical simulation. Monte Carlo simulation is a more sophisticated technique than historical simulation is. In Monte Carlo simulation, the most important decision is the choice of functional form of the statistical distribution of decision variables/return drivers. Multivariate normal distribution is often used in investment research, owing to its simplicity. However, a multivariate normal distribution cannot account for negative skewness and fat tails observed in factor and asset returns. The Monte Carlo simulation technique makes use of the inverse transformation method—the process of converting a randomly generated uniformly distributed number into a simulated value of a random variable of a desired distribution. Sensitivity analysis, a technique for exploring how a target variable and risk profiles are affected by changes in input variables, can further help investors understand the limitations of conventional Monte Carlo simulation (which typically assumes a multivariate normal distribution as a starting point). A multivariate skewed t-distribution takes into account skewness and kurtosis but requires estimation of more parameters and thus is more likely to suffer from larger estimation errors."
Branded Image Link Added to Refresher Reading,,1,"The authors of this article derive their formula using the risk-neutral variances of the stock, the market, and an average stock, which can be computed directly from index and stock option prices. Their resulting formula performs well for typical stocks (e.g., those in the S&P 500 Index), both in and out of sample, for periods up to two years.","Make sure you can add a BrandedImageLink component as an Insert Option on the Refresher Reading Base Template, which is on the Refresher Reading structure (so if you right-click on the parent item of a Refresher Reading, that is where you should be able to insert a BrandedimageLink). The Branded Image Link should render above Primary Content Asset. And it should render in the same place on the page (under the title and metadata) regardless of whether or not a Primary content Asset is added.",https://www.cfainstitute.org/membership/professional-development/refresher-readings/2020/QA-Test-Refresher-Reading-1,,"In today's competitive business environment, establishing and maintaining a strong brand image is essential for companies seeking long-term success and market relevance. A brand's image encompasses various aspects, including its reputation, identity, and perception among consumers. As such, companies continuously explore innovative strategies to enhance their brand image and foster meaningful connections with their target audience. One such strategy gaining traction in marketing circles is the integration of branded image links into refresher reading materials. These materials, often utilized for training, professional development, or internal communications, serve as valuable resources for employees to refresh their knowledge, acquire new skills, and stay updated on industry trends. By incorporating branded image links into these materials, companies aim to reinforce their brand identity, convey key messages, and engage employees in a visually compelling manner. The inclusion of branded image links in refresher reading materials presents a multifaceted approach to brand communication and engagement. Unlike traditional text-based content, visual elements such as images and graphics have a profound impact on human cognition and memory retention. Studies have shown that visuals are processed faster by the brain and are more likely to be remembered than text alone. By leveraging the power of visual storytelling, companies can effectively capture the attention of their audience and leave a lasting impression. Branded image links offer companies a unique opportunity to showcase their brand personality, values, and offerings in a visually appealing format. Whether highlighting product features, showcasing corporate culture, or conveying brand narratives, these images serve as tangible representations of the brand's identity. By strategically selecting and placing images that align with their brand positioning, companies can create a cohesive and memorable brand experience for their audience. Moreover, the integration of branded image links into refresher reading materials facilitates seamless alignment with digital platforms and social media channels. In an increasingly digital-centric world, visual content is king, driving engagement and interaction across online channels. By incorporating visually appealing images into their training materials, companies can extend their reach and amplify their brand presence on digital platforms, thereby enhancing brand visibility and recognition. Furthermore, branded image links in refresher reading materials serve as effective tools for reinforcing key messages and concepts. Through carefully curated visuals, companies can illustrate complex ideas, convey abstract concepts, and provide real-world examples that resonate with employees. This approach not only enhances understanding but also encourages active participation and knowledge retention among learners. Additionally, the integration of branded image links into refresher reading materials enables companies to personalize the learning experience for their employees. By tailoring the content to reflect the company's unique brand identity and culture, companies can create a sense of belonging and alignment among employees. This personalized approach fosters employee engagement, loyalty, and a deeper connection to the brand. However, it is essential for companies to exercise caution and ensure that the use of branded image links aligns with their overall branding strategy and objectives. Careful consideration should be given to the selection, placement, and context of images to ensure consistency with the brand's values and messaging. Moreover, companies should regularly review and update their image libraries to reflect evolving brand priorities and industry trends. In conclusion, the integration of branded image links into refresher reading materials represents a strategic approach for enhancing brand communication, engaging employees, and fostering a culture of continuous learning within organizations. By leveraging the power of visual storytelling, companies can create compelling narratives that resonate with their audience, drive brand loyalty, and ultimately contribute to business success in the long run."
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BFhwo6izYK0",
    "outputId": "782c873d-fce1-4c76-b8b1-c01445990623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q pandas openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "NQgcbaZ1uqv9",
    "outputId": "e7b360ce-896f-4c6d-9e33-8651d68404be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions generated: 40\n",
      "Question: In a data analysis project, which of the following steps typically comes first?\n",
      "\n",
      "A) Data collection\n",
      "B) Data cleaning\n",
      "C) Data analysis\n",
      "D) Data visualization\n",
      "\n",
      "Correct Answer: A) Data collection \n",
      "\n",
      "Which step in a data analysis project involves collecting, cleaning, and organizing the data before performing any analysis?\n",
      "\n",
      "A) Data visualization\n",
      "B) Hypothesis testing\n",
      "C) Data preprocessing\n",
      "D) Model building\n",
      "\n",
      "Correct answer: C) Data preprocessing \n",
      "\n",
      "Question: What is the primary objective of data preparation and wrangling in the context of financial analysis?\n",
      "\n",
      "A) To manipulate data to support preconceived notions or biases\n",
      "B) To clean and transform raw data into a usable format for analysis\n",
      "C) To simplify data analysis by ignoring outliers and missing values\n",
      "D) To increase the size of the dataset for better statistical significance\n",
      "\n",
      "Correct Answer: B) To clean and transform raw data into a usable format for analysis \n",
      "\n",
      "Which of the following steps is typically NOT a part of data preparation and wrangling?\n",
      "\n",
      "A) Collecting the data\n",
      "B) Cleaning and transforming the data\n",
      "C) Analyzing the data\n",
      "D) Dealing with missing values\n",
      "\n",
      "Correct Answer: C) Analyzing the data \n",
      "\n",
      "Question: Which of the following is an objective of data exploration?\n",
      "\n",
      "A) Predict future outcomes\n",
      "B) Draw conclusions from data\n",
      "C) Identify patterns and relationships\n",
      "D) Develop hypotheses\n",
      "\n",
      "Correct Answer: C) Identify patterns and relationships \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = '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'  # Use your actual API key\n",
    "\n",
    "# Function adapted for v1/chat/completions to generate questions\n",
    "def generate_questions_from_outcome(outcome, num_questions):\n",
    "    questions = []\n",
    "    for _ in range(num_questions):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a knowledgeable tutor tasked with creating CFA-level questions based on specific learning outcomes. Generate a question with four options (A, B, C, D), clearly indicating the correct answer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Learning outcome: {outcome}\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if response.choices:\n",
    "            question_text = response.choices[0].message['content'].strip()\n",
    "            if question_text:  # Ensure non-empty responses are added\n",
    "                questions.append(question_text)\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "question_bank = []\n",
    "\n",
    "# For each topic, generate questions from each of its learning outcomes\n",
    "for index, row in df.iterrows():\n",
    "    if len(question_bank) >= 50:\n",
    "        break  # Stop if we have already generated 50 questions\n",
    "\n",
    "    learning_outcomes = row['Learning_Outcomes'].split(';')  # Adjust if your format is different\n",
    "    num_questions_per_outcome = max(1, 50 // (len(learning_outcomes) * 3))  # Adjust based on your desired distribution\n",
    "\n",
    "    for outcome in learning_outcomes:\n",
    "        if len(question_bank) >= 50:\n",
    "            break  # Check again in case we reached the limit during question generation\n",
    "        questions = generate_questions_from_outcome(outcome, num_questions_per_outcome)\n",
    "        question_bank.extend(questions[:num_questions_per_outcome])  # Ensure not to exceed per outcome\n",
    "\n",
    "# Output the number of generated questions and the first few for review\n",
    "print(f\"Total questions generated: {len(question_bank)}\")\n",
    "for question in question_bank[:5]:  # Display some examples\n",
    "    print(question, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZD0r2u15zMG",
    "outputId": "4bafb976-0aa0-430d-a349-6d905336d17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total question-answer pairs generated: 40\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = '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'  # Use your actual API key\n",
    "\n",
    "def generate_questions_from_outcome(outcome, num_questions):\n",
    "    question_answers = []  # This will store tuples of (question, answer)\n",
    "    for _ in range(num_questions):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a knowledgeable tutor tasked with creating CFA-level questions based on specific learning outcomes. Generate a question with four options (A, B, C, D), clearly indicating the correct answer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Learning outcome: {outcome}\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if response.choices:\n",
    "            text = response.choices[0].message['content'].strip()\n",
    "            if text:  # Ensure non-empty responses are added\n",
    "                # Assuming the correct answer is clearly marked in the generated text\n",
    "                # You'll need to adjust the parsing below based on how your answer is indicated\n",
    "                # This is a placeholder for how you might separate the question from the answer\n",
    "                question, answer = text.rsplit('\\n', 1)  # This assumes the last line is the answer\n",
    "                question_answers.append((question, answer))\n",
    "\n",
    "    return question_answers\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "question_answer_bank = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if len(question_answer_bank) >= 50:\n",
    "        break  # Stop if we have already generated 50 question-answer pairs\n",
    "\n",
    "    learning_outcomes = row['Learning_Outcomes'].split(';')  # Adjust if your format is different\n",
    "    num_questions_per_outcome = max(1, 50 // (len(learning_outcomes) * 3))  # Adjust based on your desired distribution\n",
    "\n",
    "    for outcome in learning_outcomes:\n",
    "        if len(question_answer_bank) >= 50:\n",
    "            break  # Check again in case we reached the limit during question generation\n",
    "        qas = generate_questions_from_outcome(outcome, num_questions_per_outcome)\n",
    "        question_answer_bank.extend(qas[:num_questions_per_outcome])  # Ensure not to exceed per outcome\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "qa_df = pd.DataFrame(question_answer_bank, columns=['Questions', 'Answers'])\n",
    "qa_df.to_csv('/content/question_answer_bank.csv', index=False)\n",
    "\n",
    "print(f\"Total question-answer pairs generated: {len(question_answer_bank)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIB7mB3yz80J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
